{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test AttentionDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from datasets.tsp import gen_fully_connected_graph\n",
    "from models.decoder import AttentionDecoder\n",
    "from torch_geometric.data import Batch, Data\n",
    "from torch_geometric.nn import global_max_pool\n",
    "from torch_geometric.utils import to_dense_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttentionDecoder(\n",
       "  (query_proj): Linear(in_features=4, out_features=4, bias=True)\n",
       "  (key_proj): Linear(in_features=4, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_dim = 4\n",
    "num_heads = 2\n",
    "attn = AttentionDecoder(query_dim=embed_dim, embed_dim=embed_dim, num_heads=num_heads)\n",
    "attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = gen_fully_connected_graph(5)\n",
    "g2 = gen_fully_connected_graph(10)\n",
    "g1.mask = torch.ones((51), dtype=torch.bool)\n",
    "g2.mask = torch.ones((101), dtype=torch.bool)\n",
    "g1.mask[0:4] = False\n",
    "g2.mask[0:4] = False\n",
    "data_list = [g1 if (i % 2) == 0 else g2 for i in range(64)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = Batch.from_data_list(data_list)\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_batch = to_dense_batch(batch.x, batch.batch)[0]\n",
    "dense_mask = to_dense_batch(batch.mask, batch.batch)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 64, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = dense_batch.permute(102)\n",
    "key.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 10])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = dense_mask.permute(021)\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = global_max_pool(batch.x, batch.batch)\n",
    "query = query[None, :, :]\n",
    "query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_weight = attn(query, key, ~mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[False, False, False, False,  True, False, False, False, False, False]],\n",
       "\n",
       "        [[False, False, False, False,  True,  True,  True,  True,  True,  True]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.1521, 0.1673, 0.1746, 0.1700,\n",
       "          0.1728, 0.1631]]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weight.exp()[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4],\n",
       "        [7]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weight.exp().squeeze().multinomial(1)[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test TSP Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets.tsp import gen_fully_connected_graph\n",
    "from environments.tsp import TSPEnv\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.utils import to_dense_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 10\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(batch=[50], edge_index=[2, 500], pos=[50, 2], x=[50, 4])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = gen_fully_connected_graph(num_nodes)\n",
    "g_list = [g for _ in range(batch_size)]\n",
    "batch = Batch.from_data_list(g_list)\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_pos, dense_mask = to_dense_batch(batch.pos, batch.batch)\n",
    "assert dense_mask.all()\n",
    "node_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [False,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [False,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [False,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [False,  True,  True,  True,  True,  True,  True,  True,  True,  True]])\n"
     ]
    }
   ],
   "source": [
    "env = TSPEnv(node_pos)\n",
    "assert env.num_nodes == num_nodes\n",
    "assert env.batch_size == batch_size\n",
    "print(env._avail_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TSPState(first_node=tensor([[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]]), pre_node=tensor([[9],\n",
       "         [4],\n",
       "         [2],\n",
       "         [1],\n",
       "         [8]]), avail_mask=tensor([[False,  True,  True,  True,  True,  True,  True,  True,  True, False],\n",
       "         [False,  True,  True,  True, False,  True,  True,  True,  True,  True],\n",
       "         [False,  True, False,  True,  True,  True,  True,  True,  True,  True],\n",
       "         [False, False,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "         [False,  True,  True,  True,  True,  True,  True,  True, False,  True]])),\n",
       " tensor([0., 0., 0., 0., 0.]),\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = env.random_action()\n",
    "env.step(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TSPState(first_node=tensor([[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]]), pre_node=tensor([[1],\n",
       "         [5],\n",
       "         [5],\n",
       "         [2],\n",
       "         [6]]), avail_mask=tensor([[False, False, False, False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False, False, False, False]])),\n",
       " tensor([-6.7641, -6.1001, -7.0537, -6.4557, -7.4225]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "done = False\n",
    "while not done:\n",
    "    state, reward, done, _ = env.step(env.random_action())\n",
    "state, reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test TSPAgent, TSPCritic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "import torch\n",
    "from datasets.tsp import gen_fully_connected_graph\n",
    "from environments.tsp import TSPEnv\n",
    "from models.tsp_agents import TSPAgent, TSPCritic\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.utils import to_dense_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 10\n",
    "batch_size = 64\n",
    "\n",
    "class args:\n",
    "    input_dim = 4\n",
    "    embed_dim = 64\n",
    "    num_embed_layers = 2\n",
    "    num_gnn_layers = 2\n",
    "    encoder_num_heads = 1\n",
    "    decoder_num_heads = 1\n",
    "    bias = True\n",
    "    pooling_method = \"add\"\n",
    "    decode_type = \"sampling\"\n",
    "    eval_batch_size = 64\n",
    "    warmup_batch_size = 256\n",
    "    device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TSPAgent(args).to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic = TSPCritic(args).to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = Batch.from_data_list([gen_fully_connected_graph(num_nodes) for _ in range(batch_size)])\n",
    "batch = batch.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TSP Environment, with 64 graphs of size 10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_pos = to_dense_batch(batch.pos, batch.batch)[0]\n",
    "env = TSPEnv(node_pos)\n",
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(batch=[640], edge_index=[2, 6400], pos=[640, 2], x=[640, 64])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encode(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "eval() missing 1 required positional argument: 'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-4d9643feef35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcritic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: eval() missing 1 required positional argument: 'target'"
     ]
    }
   ],
   "source": [
    "critic.eval(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_p_s = []\n",
    "selected_s = []\n",
    "reward_s = []\n",
    "done = False\n",
    "state = env.reset(node_pos)\n",
    "step = 0\n",
    "while (not done) and (step < 999):\n",
    "    selected, log_p = model(state)\n",
    "    state, reward, done, _ = env.step(selected)\n",
    "    log_p_s.append(log_p)\n",
    "    selected_s.append(selected)\n",
    "    reward_s.append(reward)\n",
    "    step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = torch.stack(selected_s, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "logps = torch.stack(log_p_s, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-12.8018, -12.8018, -12.8018, -12.8018, -12.8018, -12.8018, -12.8018,\n",
       "        -12.8018, -12.8018, -12.8018, -12.8018, -12.8018, -12.8018, -12.8018,\n",
       "        -12.8018, -12.8018, -12.8018, -12.8018, -12.8018, -12.8018, -12.8018,\n",
       "        -12.8018, -12.8018, -12.8018, -12.8018, -12.8018, -12.8018, -12.8018,\n",
       "        -12.8018, -12.8018, -12.8018, -12.8018, -12.8018, -12.8018, -12.8018,\n",
       "        -12.8018, -12.8018, -12.8018, -12.8018, -12.8018, -12.8018, -12.8018,\n",
       "        -12.8018, -12.8018, -12.8018, -12.8018, -12.8018, -12.8018, -12.8018,\n",
       "        -12.8018, -12.8018, -12.8018, -12.8018, -12.8018, -12.8018, -12.8018,\n",
       "        -12.8018, -12.8018, -12.8018, -12.8018, -12.8018, -12.8018, -12.8018,\n",
       "        -12.8018], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_likelihood = logps.gather(2, seqs).squeeze().sum(1)\n",
    "log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from args import get_args\n",
    "from datasets.tsp import TSPDataset\n",
    "from train import rollout, validate\n",
    "from rl_algorithms.reinforce import _calc_log_likelihood\n",
    "from train import warmup_baseline\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = TSPDataset(1000, min_num_node=num_nodes, max_num_node=num_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.8022, -3.8708, -5.5611,  ..., -3.2411, -4.6239, -4.9271])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rollout(model, dataset, env, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n",
      "Validation overall avg_cost: 4.079802513122559 +- 0.02389952540397644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(4.0798)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(model, dataset, env, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 22.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warmup Critic Baseline with training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(\n",
    "    [{\"params\": model.parameters(), \"lr\": 0.001}] + \n",
    "    [{\"params\": critic.parameters(), \"lr\": 0.001}]\n",
    ")\n",
    "warmup_baseline(critic, dataset, env, optimizer, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:47<00:00, 20.99it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(1000)):\n",
    "    batch = batch.to(args.device)\n",
    "    model.train()\n",
    "    model.encode(batch)\n",
    "    model.set_decode_type(\"sampling\")\n",
    "    log_p_s = []\n",
    "    selected_s = []\n",
    "    reward_s = []\n",
    "    done = False\n",
    "    state = env.reset(to_dense_batch(batch.pos, batch.batch)[0])\n",
    "    step = 0\n",
    "    while (not done) and (step < 999):\n",
    "        selected, log_p = model(state)\n",
    "#         selected = torch.tensor([[step+1]], dtype=torch.long, device=args.device)\n",
    "        state, reward, done, _ = env.step(selected)\n",
    "        log_p_s.append(log_p)\n",
    "        selected_s.append(selected)\n",
    "        reward_s.append(reward)\n",
    "        step += 1\n",
    "\n",
    "    _log_p = torch.stack(log_p_s, 1)\n",
    "    actions = torch.stack(selected_s, 1)\n",
    "    log_likelihood = _calc_log_likelihood(_log_p, actions)\n",
    "    reward = -reward.unsqueeze(-1)\n",
    "    bl_val, bl_loss = critic.eval(batch, reward)\n",
    "    rl_loss = ((reward-bl_val)*log_likelihood).mean()\n",
    "    loss = rl_loss + bl_loss\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3749, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor([-11.9626, -13.4902, -12.8316, -12.7669, -12.3703, -12.4275, -12.1155,\n",
      "        -11.9612, -12.8306, -12.7549, -12.7864, -12.8981, -12.7001, -13.1047,\n",
      "        -13.1736, -12.8995, -12.4332, -13.2156, -11.6555, -13.6180, -13.1413,\n",
      "        -13.3393, -12.5452, -12.1836, -12.1994, -13.1358, -12.7499, -13.2295,\n",
      "        -11.7873, -12.8880, -12.9807, -13.2419, -12.5407, -13.2133, -12.7517,\n",
      "        -13.2434, -13.2781, -12.7076, -12.6697, -13.0293, -12.4183, -12.3979,\n",
      "        -13.3256, -13.0834, -13.2280, -12.6623, -12.3575, -12.0317, -12.2767,\n",
      "        -12.9623, -11.6372, -13.3611, -12.3948, -12.2976, -12.5602, -12.6557,\n",
      "        -12.4446, -12.2365, -13.7505, -12.2146, -13.6701, -13.2010, -12.7464,\n",
      "        -12.5830], device='cuda:0', grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(rl_loss)\n",
    "print(bl_loss)\n",
    "print(log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1451, 0.1215, 0.1905, 0.1667, 0.1898, 0.2674, 0.3751, 0.5984, 1.0000],\n",
       "        [0.1396, 0.1160, 0.0994, 0.1837, 0.2139, 0.2614, 0.3131, 0.5169, 1.0000],\n",
       "        [0.1140, 0.1405, 0.1660, 0.1308, 0.2130, 0.3266, 0.3131, 0.5600, 1.0000],\n",
       "        [0.1459, 0.0923, 0.1592, 0.2028, 0.2299, 0.3024, 0.3132, 0.5790, 1.0000]],\n",
       "       device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_log_p.exp().gather(2, actions).squeeze(-1)[0:8:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.1039, 0.1433, 0.0961, 0.1013, 0.1098, 0.1128, 0.1124, 0.1451,\n",
      "         0.0753],\n",
      "        [0.0000, 0.1215, 0.1675, 0.1124, 0.1185, 0.1284, 0.1320, 0.1315, 0.0000,\n",
      "         0.0881],\n",
      "        [0.0000, 0.0000, 0.1905, 0.1280, 0.1349, 0.1462, 0.1502, 0.1497, 0.0000,\n",
      "         0.1005],\n",
      "        [0.0000, 0.0000, 0.0000, 0.1581, 0.1667, 0.1806, 0.1856, 0.1850, 0.0000,\n",
      "         0.1240],\n",
      "        [0.0000, 0.0000, 0.0000, 0.1898, 0.0000, 0.2167, 0.2226, 0.2219, 0.0000,\n",
      "         0.1490],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2674, 0.2748, 0.2738, 0.0000,\n",
      "         0.1839],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3751, 0.3739, 0.0000,\n",
      "         0.2509],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5984, 0.0000,\n",
      "         0.4016],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<ExpBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(_log_p[0].exp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(reward)\n",
    "# print(bl_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = batch.to_data_list()[0]\n",
    "g.x = torch.stack([torch.arange(10).type(torch.float)]*4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.edge_index[:,0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.nn import TransformerConv\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "gnn = TransformerConv(4,4)\n",
    "\n",
    "opt = optim.Adam(\n",
    "    [{\"params\": gnn.parameters(), \"lr\": 0.001}]\n",
    ")\n",
    "target = torch.arange(10).type(torch.float)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    out = gnn(g.x, g.edge_index).mean(1)\n",
    "    loss = F.mse_loss(out, target)\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3300, 1.1001, 1.9340, 2.8558, 3.8780, 4.9753, 6.0786, 7.1146, 8.0510,\n",
       "        8.8963], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnn(g.x, g.edge_index).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0192, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
