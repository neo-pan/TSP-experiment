{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test AttentionDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from datasets.tsp import gen_fully_connected_graph\n",
    "from models.decoder import AttentionDecoder\n",
    "from torch_geometric.data import Batch, Data\n",
    "from torch_geometric.nn import global_max_pool\n",
    "from torch_geometric.utils import to_dense_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 4\n",
    "num_heads = 2\n",
    "attn = AttentionDecoder(query_dim=embed_dim, embed_dim=embed_dim, num_heads=num_heads)\n",
    "attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = gen_fully_connected_graph(5)\n",
    "g2 = gen_fully_connected_graph(10)\n",
    "g1.mask = torch.ones((51), dtype=torch.bool)\n",
    "g2.mask = torch.ones((101), dtype=torch.bool)\n",
    "g1.mask[0:4] = False\n",
    "g2.mask[0:4] = False\n",
    "data_list = [g1 if (i % 2) == 0 else g2 for i in range(64)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = Batch.from_data_list(data_list)\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_batch = to_dense_batch(batch.x, batch.batch)[0]\n",
    "dense_mask = to_dense_batch(batch.mask, batch.batch)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = dense_batch.permute(102)\n",
    "key.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = dense_mask.permute(021)\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = global_max_pool(batch.x, batch.batch)\n",
    "query = query[None, :, :]\n",
    "query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_weight = attn(query, key, ~mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_weight.exp()[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_weight.exp().squeeze().multinomial(1)[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test TSP Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets.tsp import gen_fully_connected_graph\n",
    "from environments.tsp import TSPEnv\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.utils import to_dense_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 10\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gen_fully_connected_graph(num_nodes)\n",
    "g_list = [g for _ in range(batch_size)]\n",
    "batch = Batch.from_data_list(g_list)\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_pos, dense_mask = to_dense_batch(batch.pos, batch.batch)\n",
    "assert dense_mask.all()\n",
    "node_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TSPEnv(node_pos)\n",
    "assert env.num_nodes == num_nodes\n",
    "assert env.batch_size == batch_size\n",
    "print(env._avail_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = env.random_action()\n",
    "env.step(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = False\n",
    "while not done:\n",
    "    state, reward, done, _ = env.step(env.random_action())\n",
    "state, reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test TSPAgent, TSPCritic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "import torch\n",
    "from datasets.tsp import gen_complete_graph\n",
    "from environments.tsp import TSPEnv\n",
    "from models.tsp_agent import TSPAgent\n",
    "from models.tsp_baseline import CriticBaseline\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.utils import to_dense_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 10\n",
    "batch_size = 64\n",
    "\n",
    "class args:\n",
    "    input_dim = 4\n",
    "    embed_dim = 64\n",
    "    num_embed_layers = 2\n",
    "    num_gnn_layers = 2\n",
    "    encoder_num_heads = 1\n",
    "    decoder_num_heads = 1\n",
    "    bias = True\n",
    "    pooling_method = \"add\"\n",
    "    decode_type = \"sampling\"\n",
    "    eval_batch_size = 64\n",
    "    warmup_batch_size = 256\n",
    "    device = torch.device(\"cp\")\n",
    "    max_grad_norm = 1.0\n",
    "    tanh_clipping = 0\n",
    "    normalization = \"batch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TSPAgent(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic = CriticBaseline(args).to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(param.numel() for param in critic.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = Batch.from_data_list([gen_fully_connected_graph(num_nodes) for _ in range(batch_size)])\n",
    "batch = batch.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_pos = to_dense_batch(batch.pos, batch.batch)[0]\n",
    "env = TSPEnv(node_pos)\n",
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encode(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_p_s = []\n",
    "selected_s = []\n",
    "reward_s = []\n",
    "done = False\n",
    "state = env.reset(node_pos)\n",
    "step = 0\n",
    "while (not done) and (step < 999):\n",
    "    selected, log_p = model(state)\n",
    "    state, reward, done, _ = env.step(selected)\n",
    "    log_p_s.append(log_p)\n",
    "    selected_s.append(selected)\n",
    "    reward_s.append(reward)\n",
    "    step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = torch.stack(selected_s, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logps = torch.stack(log_p_s, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihood = logps.gather(2, seqs).squeeze().sum(1)\n",
    "log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = model.encode(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "ll = logps[:, :, 1:]+0.001\n",
    "ll\n",
    "# loss = nn.NLLLoss()(, seqs.squeeze(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import BatchNorm\n",
    "norm = BatchNorm(args.embed_dim).to(args.device)\n",
    "norm(b.x.to(args.device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from args import get_args\n",
    "from datasets.tsp import TSPDataset\n",
    "from train import rollout, validate\n",
    "from rl_algorithms.reinforce import _calc_log_likelihood, clip_grad_norms\n",
    "from train import warmup_baseline\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TSPDataset(1000, args.graph_size, args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout(model, dataset, env, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate(model, dataset, env, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(\n",
    "    [{\"params\": model.parameters(), \"lr\": 0.001}] + \n",
    "    # [{\"params\": critic.parameters(), \"lr\": 0.001}]\n",
    ")\n",
    "# warmup_baseline(critic, dataset, env, optimizer, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(10)):\n",
    "    batch = batch.to(args.device)\n",
    "    model.train()\n",
    "    model.set_decode_type(\"sampling\")\n",
    "    log_p_s = []\n",
    "    selected_s = []\n",
    "    reward_s = []\n",
    "    done = False\n",
    "    state = env.reset(to_dense_batch(batch.pos, batch.batch)[0])\n",
    "    embed_data = model.init_embed(batch)\n",
    "    node_embeddings, graph_feat = model.encoder(embed_data)\n",
    "    fixed = model.precompute_fixed(node_embeddings, graph_feat)\n",
    "    step = 0\n",
    "    while (not done) and (step < 999):\n",
    "        selected, log_p = model(state, fixed)\n",
    "        state, reward, done, _ = env.step(selected)\n",
    "        log_p_s.append(log_p)\n",
    "        selected_s.append(selected)\n",
    "        reward_s.append(reward)\n",
    "        step += 1\n",
    "\n",
    "    _log_p = torch.stack(log_p_s, 1)\n",
    "    actions = torch.stack(selected_s, 1)\n",
    "    log_likelihood = _calc_log_likelihood(_log_p, actions)\n",
    "    reward = -(reward_s[-1])\n",
    "    # bl_val, bl_loss = critic.eval(batch, reward)\n",
    "    rl_loss = (reward*log_likelihood).mean()\n",
    "    # loss = rl_loss + bl_loss\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    rl_loss.backward()\n",
    "    grad_norms = clip_grad_norms(optimizer.param_groups, args.max_grad_norm)\n",
    "    optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(optimizer.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_log_p.exp().gather(2, actions).squeeze(-1)[0:8:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(_log_p[0].exp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(reward)\n",
    "# print(bl_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test MST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx.algorithms.tree.mst as mst\n",
    "from datasets.tsp import gen_fully_connected_graph\n",
    "from torch_geometric.transforms import distance\n",
    "from torch_geometric.utils import to_networkx, from_networkx, to_dense_batch\n",
    "from torch_geometric.data import Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = gen_fully_connected_graph(50)\n",
    "graph = Batch.from_data_list([graph] * 5)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = distance.Distance(cat=False)(graph)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng = to_networkx(graph, edge_attrs=[\"edge_attr\"], to_undirected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_mst = mst.minimum_spanning_tree(ng, \"edge_attr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mst_len = []\n",
    "for e in ng_mst.edges:\n",
    "    mst_len.append(ng_mst.edges[e][\"edge_attr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(mst_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "nx.draw(ng_mst, pos=graph.pos.numpy())\n",
    "ng_mst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([edge_value[\"edge_attr\"] for edge_value in ng_mst.edges.values()])\n",
    "mst_g = from_networkx(ng_mst)\n",
    "mst_b = Batch()\n",
    "mst_b.batch = graph.batch\n",
    "mst_b.edge_index = mst_g.edge_index\n",
    "mst_b.x = graph.x\n",
    "to_dense_batch(mst_b.x, mst_b.batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validateto_data_listto_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from args import get_args\n",
    "from environments.tsp import TSPEnv\n",
    "from models.tsp_agent import TSPAgent\n",
    "from train import rollout, validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args([])\n",
    "args.device = torch.device(\"cuda\")\n",
    "model = TSPAgent(args).to(args.device)\n",
    "model_path = \"/home/pxh/TSP-experiment/outputs/tsp_50/run_20201217T165809/epoch-21.pt\"\n",
    "dataste_path = \"/home/pxh/TSP-experiment/datasets/test/test-50-with-optimal.pk\"\n",
    "\n",
    "val_dataset = torch.load(dataste_path)\n",
    "load_data = torch.load(model_path)\n",
    "model.load_state_dict(load_data[\"model\"])\n",
    "env = TSPEnv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = rollout(model, val_dataset, env, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-out.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(torch.tensor([d.len for d in val_dataset]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1672.2463/569.4701"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Batch\n",
    "b = Batch.from_data_list([val_dataset[10]]).to(args.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset(b.pos.unsqueeze(0))\n",
    "logp_s = []\n",
    "done = False\n",
    "while not done:\n",
    "    model.eval()\n",
    "    model.set_decode_type(\"sampling\")\n",
    "    model.encode(b)\n",
    "    action, log_p = model(state)\n",
    "    logp_s.append(log_p)\n",
    "    state, r, done, _ = env.step(action)\n",
    "    \n",
    "-r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(49):\n",
    "#     plt.plot(torch.arange(logp_s[i].size(1)), logp_s[i].exp().detach().cpu().squeeze())\n",
    "#     plt.show()\n",
    "#     print(i)\n",
    "#     print(logp_s[i].exp().detach().cpu().squeeze().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mst_set = torch.load('/home/pxh/TSP-experiment/datasets/test/mst-10-100-optimal.pk')\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "tsp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in mst_set:\n",
    "    x.append(data.num_nodes)\n",
    "    y.append((data.concorde_len / data.mst_len).item())\n",
    "    tsp.append(data.concorde_len.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, tsp)"
   ]
  },
  {
   "source": [
    "## Test Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets.tsp\n",
    "from torch_geometric.transforms import Distance, KNNGraph\n",
    "from torch_geometric.utils import sort_edge_index\n",
    "from torch_geometric.nn import knn_graph\n",
    "from torch_geometric.data import Data\n",
    "import torch.multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lprun -f datasets.tsp.gen_fully_connected_graph -f datasets.tsp.gen_knn_graph -f Data.__init__ datasets.tsp.gen_knn_graph(50,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(datasets.tsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f  datasets.tsp.gen_complete_graph datasets.tsp.gen_complete_graph(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.reshape(index.T, [-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.stack(edge_attr.chunk(50)).squeeze().topk(k=5, dim=1, largest=False).indices[:, None, :].expand(50,2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = torch.stack(edge_index.chunk(50,dim=1)).gather(dim=2, index=idx)\n",
    "knn.permute(1,0,2).reshape(2,250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack(edge_attr.chunk(50)).squeeze().topk(k=5, dim=1, largest=False).values.reshape(250,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(knn1.edge_index==knn2.edge_index).all()"
   ]
  },
  {
   "source": [
    "## Test 2-opt environment"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<module 'environments.tsp_2opt' from '/home/pxh/Develop/TSP-experiment/environments/tsp_2opt.py'>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import environments.tsp_2opt as tsp2opt\n",
    "import torch\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "reload(tsp2opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = tsp2opt.TSP2OPTEnv()\n",
    "node_pos = torch.empty((10, 5, 2)).uniform_(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0, 4, 3, 2, 1],\n",
       "        [1, 3, 4, 2, 0],\n",
       "        [4, 1, 2, 3, 0],\n",
       "        [4, 3, 0, 2, 1],\n",
       "        [3, 1, 2, 4, 0],\n",
       "        [1, 3, 0, 4, 2],\n",
       "        [0, 3, 2, 4, 1],\n",
       "        [3, 0, 4, 1, 2],\n",
       "        [0, 3, 2, 1, 4],\n",
       "        [1, 2, 3, 0, 4]])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "state = env.reset(T=10, node_pos=node_pos)\n",
    "state.curr_tour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1, 4],\n",
       "        [3, 0],\n",
       "        [0, 3],\n",
       "        [3, 1],\n",
       "        [2, 4],\n",
       "        [3, 0],\n",
       "        [1, 3],\n",
       "        [2, 0],\n",
       "        [0, 3],\n",
       "        [0, 3]])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "action = env.random_action()\n",
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s, r, d, _ = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4],\n",
       "        [1, 4, 3, 2, 0],\n",
       "        [4, 1, 2, 3, 0],\n",
       "        [4, 3, 0, 2, 1],\n",
       "        [3, 1, 0, 4, 2],\n",
       "        [1, 0, 3, 4, 2],\n",
       "        [0, 4, 2, 3, 1],\n",
       "        [3, 0, 4, 1, 2],\n",
       "        [0, 3, 2, 1, 4],\n",
       "        [1, 2, 3, 0, 4]])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "s.curr_tour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "         [3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
       "         [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]],\n",
       "\n",
       "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [4, 4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
       "         [3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
       "         [2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[4, 4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "         [3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[4, 4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
       "         [3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "\n",
       "        [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [4, 4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
       "         [2, 2, 2, 2, 2, 2, 2, 2, 2, 2]],\n",
       "\n",
       "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
       "         [4, 4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
       "         [2, 2, 2, 2, 2, 2, 2, 2, 2, 2]],\n",
       "\n",
       "        [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [4, 4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
       "         [2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "         [3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "\n",
       "        [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [4, 4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [2, 2, 2, 2, 2, 2, 2, 2, 2, 2]],\n",
       "\n",
       "        [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
       "         [2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]],\n",
       "\n",
       "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "         [3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]]])"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = []\n",
    "state = env.reset(T=100, node_pos=node_pos)\n",
    "done = False\n",
    "while not done:\n",
    "    action = env.random_action()\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    rewards.append(reward)\n",
    "torch.cat(rewards, dim=1).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.best_edge_list.shape"
   ]
  },
  {
   "source": [
    "## Test 2-opt model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<module 'models.tsp_2opt_agent' from '/home/pxh/Develop/TSP-experiment/models/tsp_2opt_agent.py'>"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import torch\n",
    "from datasets.tsp import gen_knn_graph\n",
    "import models.encoder as encoder\n",
    "import models.tsp_2opt_agent as tsp2opt\n",
    "import environments.tsp_2opt as env2opt\n",
    "from importlib import reload\n",
    "from torch_geometric.utils import to_undirected, remove_self_loops, contains_self_loops, to_dense_batch\n",
    "from torch_geometric.data import Batch\n",
    "from tqdm.notebook import tqdm\n",
    "from torch_discounted_cumsum import discounted_cumsum_right\n",
    "reload(tsp2opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 20\n",
    "batch_size = 64\n",
    "\n",
    "class args:\n",
    "    graph_size = 20\n",
    "    node_dim = 2\n",
    "    edge_dim = 1\n",
    "    embed_dim = 64\n",
    "    num_gnn_layers = 2\n",
    "    tour_gnn_layers = 5\n",
    "    encoder_num_heads = 1\n",
    "    decoder_num_heads = 1\n",
    "    bias = True\n",
    "    pooling_method = \"mean\"\n",
    "    tour_pooling_method = \"add\"\n",
    "    decode_type = \"sampling\"\n",
    "    eval_batch_size = 64\n",
    "    warmup_batch_size = 256\n",
    "    device = torch.device(\"cuda\")\n",
    "    max_grad_norm = 1.0\n",
    "    tanh_clipping = 10\n",
    "    normalization = \"batch\"\n",
    "    graph_type = \"knn\"\n",
    "    gamma = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = encoder.GNNEncoder(\n",
    "    args.embed_dim,\n",
    "    args.num_gnn_layers,\n",
    "    args.encoder_num_heads,\n",
    "    args.normalization,\n",
    "    pooling_method=args.pooling_method,\n",
    ")\n",
    "model = tsp2opt.TSP2OPTAgent(args)\n",
    "\n",
    "enc_optimizer = torch.optim.Adam(\n",
    "    [{\"params\": enc.parameters(), \"lr\": 0.0001}]\n",
    ")\n",
    "optimizer = torch.optim.Adam(\n",
    "    [{\"params\": model.parameters(), \"lr\": 0.0001}]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Batch(batch=[1280], edge_attr=[6400, 1], edge_index=[2, 6400], pos=[1280, 2], ptr=[65], x=[1280, 4])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "batch = Batch.from_data_list([gen_knn_graph(num_nodes, 5) for _ in range(batch_size)])\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_data = model.init_embed(batch)\n",
    "embed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_embedding, _ = model.encoder(embed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = env2opt.TSP2OPTEnv()\n",
    "state = env.reset(T=10, node_pos=to_dense_batch(batch.pos, batch.batch)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected, log_p = model(state, node_embedding, embed_data.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_embedding.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2af14211a18540fc8d41cea1ea2a8234"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9.546627044677734\n",
      "9.213933944702148\n",
      "9.35234546661377\n",
      "9.310626983642578\n",
      "9.460031509399414\n",
      "9.366538047790527\n",
      "9.337263107299805\n",
      "9.536606788635254\n",
      "9.327062606811523\n",
      "9.487354278564453\n",
      "9.391715049743652\n",
      "9.25745677947998\n",
      "9.30219841003418\n",
      "9.334794998168945\n",
      "9.270964622497559\n",
      "9.193643569946289\n",
      "9.312278747558594\n",
      "9.32988452911377\n",
      "9.322291374206543\n",
      "9.16451644897461\n",
      "9.310848236083984\n",
      "9.331865310668945\n",
      "9.436527252197266\n",
      "9.331438064575195\n",
      "9.326557159423828\n",
      "9.409215927124023\n",
      "9.054609298706055\n",
      "9.459001541137695\n",
      "9.422969818115234\n",
      "9.360427856445312\n",
      "9.39968204498291\n",
      "9.214611053466797\n",
      "9.345216751098633\n",
      "9.176380157470703\n",
      "9.336894989013672\n",
      "9.47273063659668\n",
      "9.210100173950195\n",
      "9.179298400878906\n",
      "9.174297332763672\n",
      "9.1559419631958\n",
      "9.434991836547852\n",
      "9.080377578735352\n",
      "9.266708374023438\n",
      "9.388861656188965\n",
      "9.217191696166992\n",
      "9.386285781860352\n",
      "9.268587112426758\n",
      "9.159870147705078\n",
      "9.19357681274414\n",
      "9.254854202270508\n",
      "9.132089614868164\n",
      "9.225378036499023\n",
      "9.182703018188477\n",
      "9.147730827331543\n",
      "9.206768035888672\n",
      "9.159401893615723\n",
      "9.394859313964844\n",
      "9.07934284210205\n",
      "9.11831283569336\n",
      "9.157183647155762\n",
      "9.182445526123047\n",
      "9.311656951904297\n",
      "9.18293571472168\n",
      "9.190999984741211\n",
      "9.118219375610352\n",
      "9.130146980285645\n",
      "9.158636093139648\n",
      "9.184584617614746\n",
      "9.186073303222656\n",
      "9.258828163146973\n",
      "9.031124114990234\n",
      "9.083792686462402\n",
      "9.206182479858398\n",
      "9.100238800048828\n",
      "9.186546325683594\n",
      "9.09422779083252\n",
      "9.264434814453125\n",
      "9.07504653930664\n",
      "9.149779319763184\n",
      "9.29829216003418\n",
      "9.008258819580078\n",
      "9.158927917480469\n",
      "9.168113708496094\n",
      "9.120409965515137\n",
      "9.15922737121582\n",
      "9.04560375213623\n",
      "9.087738990783691\n",
      "9.201251029968262\n",
      "9.21306037902832\n",
      "9.237342834472656\n",
      "9.06509017944336\n",
      "9.032083511352539\n",
      "9.195018768310547\n",
      "9.034406661987305\n",
      "9.275218963623047\n",
      "8.889920234680176\n",
      "8.992485046386719\n",
      "8.972389221191406\n",
      "9.23309326171875\n",
      "8.953368186950684\n"
     ]
    }
   ],
   "source": [
    "curr_len = []\n",
    "best_len = []\n",
    "model.cuda()\n",
    "batch = batch.to(torch.device(\"cuda\"))\n",
    "# embed_data = model.init_embed(batch)\n",
    "# embed_data.x = embed_data.x.detach()\n",
    "# embed_data.edge_attr = embed_data.edge_attr.detach()\n",
    "# node_embedding, _ = enc(embed_data)\n",
    "# enc_optimizer.zero_grad()\n",
    "for _ in tqdm(range(100)):\n",
    "    done = False\n",
    "    log_p_s = []\n",
    "    action_s = []\n",
    "    reward_s = []\n",
    "    state = env.reset(T=20, node_pos=to_dense_batch(batch.pos, batch.batch)[0])\n",
    "    embed_data = model.init_embed(batch)\n",
    "    node_embedding, _ = model.encoder(embed_data)\n",
    "    while not done:\n",
    "        action, log_p, _ = model(state, node_embedding, embed_data.batch)\n",
    "        state, reward, done, _ = env.step(action.squeeze())\n",
    "        log_p_s.append(log_p)\n",
    "        action_s.append(action)\n",
    "        reward_s.append(reward)\n",
    "    logps = torch.stack(log_p_s, dim=0)\n",
    "    actions = torch.stack(action_s, dim=0)\n",
    "    log_likelihood = logps.gather(-1, actions).squeeze(-1).mean(2).unsqueeze(2)\n",
    "    rewards = torch.stack(reward_s, dim=0)\n",
    "    returns =  discounted_cumsum_right(rewards.squeeze().T, args.gamma).T.unsqueeze(2)\n",
    "    loss = (-log_likelihood*returns).mean()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward(retain_graph=False)\n",
    "    optimizer.step()\n",
    "\n",
    "    curr_len.append(state.curr_tour_len.mean())\n",
    "    best_len.append(state.best_tour_len.mean())\n",
    "    print(state.best_tour_len.mean().item())\n",
    "\n",
    "# enc_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.curr_edge_list.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = False\n",
    "log_p_s = []\n",
    "action_s = []\n",
    "reward_s = []\n",
    "value_s = []\n",
    "state = env.reset(T=10, node_pos=to_dense_batch(batch.pos, batch.batch)[0])\n",
    "embed_data = model.init_embed(batch)\n",
    "node_embedding, _ = model.encoder(embed_data)\n",
    "while not done:\n",
    "    action, log_p, value = model(state, node_embedding, embed_data.batch)\n",
    "    state, reward, done, _ = env.step(action.squeeze())\n",
    "    log_p_s.append(log_p)\n",
    "    action_s.append(action)\n",
    "    reward_s.append(reward)\n",
    "    value_s.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns =  discounted_cumsum_right(rewards.squeeze().T, args.gamma).T.unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = torch.stack(reward_s, dim=0)\n",
    "values = torch.stack(value_s, dim=0)\n",
    "advantages = (returns - values).detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logps = torch.stack(log_p_s, dim=0)\n",
    "actions = torch.stack(action_s, dim=0)\n",
    "log_likelihood = logps.gather(-1, actions).squeeze(-1)\n",
    "log_likelihood = log_likelihood.mean(2).unsqueeze(2)\n",
    "p_loss = (-log_likelihood * advantages)\n",
    "p_loss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_loss = (returns - values).pow(2)\n",
    "v_loss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl_algorithms.reinforce_2opt import log_p_to_entropy\n",
    "entropy = log_p_to_entropy(logps).mean(2).unsqueeze(2)\n",
    "entropy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.tsp import TSPDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "val_dataset = TSPDataset(size=5, args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout(model, dataset, env, args):\n",
    "    # Put in greedy evaluation mode!\n",
    "\n",
    "    model.set_decode_type(\"greedy\")\n",
    "    model.eval()\n",
    "\n",
    "    def eval_model_bat(bat):\n",
    "        node_pos = to_dense_batch(bat.pos, bat.batch)[0]\n",
    "        done = False\n",
    "        state = env.reset(T=200, node_pos=node_pos)\n",
    "        embed_data = model.init_embed(bat)\n",
    "        node_embeddings, _ = model.encoder(embed_data)\n",
    "        while not done:\n",
    "            action, log_p, _ = model(state, node_embeddings, embed_data.batch)\n",
    "            print(action[0,0])\n",
    "            # action = env.random_action()\n",
    "            state, _, done, _ = env.step(action.squeeze())\n",
    "\n",
    "        return env.best_tour_len.cpu()\n",
    "\n",
    "    return torch.cat(\n",
    "        [eval_model_bat(bat.to(\"cuda\")) for bat in DataLoader(dataset, batch_size=5)], 0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n",
      "tensor([11], device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(10.3692)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "rollout(model, val_dataset, env, args).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_edge_index = state.curr_edge_list\n",
    "edge_index_offset = torch.arange(64) * 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('nvcc': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  },
  "metadata": {
   "interpreter": {
    "hash": "f120e1ee7e601e54dad6d026bb5c0b74c152a92403c409ff422a0cac7a36b6ed"
   }
  },
  "interpreter": {
   "hash": "f120e1ee7e601e54dad6d026bb5c0b74c152a92403c409ff422a0cac7a36b6ed"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}