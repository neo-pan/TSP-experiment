{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test AttentionDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from datasets.tsp import gen_fully_connected_graph\n",
    "from models.decoder import AttentionDecoder\n",
    "from torch_geometric.data import Batch, Data\n",
    "from torch_geometric.nn import global_max_pool\n",
    "from torch_geometric.utils import to_dense_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 4\n",
    "num_heads = 2\n",
    "attn = AttentionDecoder(query_dim=embed_dim, embed_dim=embed_dim, num_heads=num_heads)\n",
    "attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = gen_fully_connected_graph(5)\n",
    "g2 = gen_fully_connected_graph(10)\n",
    "g1.mask = torch.ones((51), dtype=torch.bool)\n",
    "g2.mask = torch.ones((101), dtype=torch.bool)\n",
    "g1.mask[0:4] = False\n",
    "g2.mask[0:4] = False\n",
    "data_list = [g1 if (i % 2) == 0 else g2 for i in range(64)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = Batch.from_data_list(data_list)\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_batch = to_dense_batch(batch.x, batch.batch)[0]\n",
    "dense_mask = to_dense_batch(batch.mask, batch.batch)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = dense_batch.permute(102)\n",
    "key.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = dense_mask.permute(021)\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = global_max_pool(batch.x, batch.batch)\n",
    "query = query[None, :, :]\n",
    "query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_weight = attn(query, key, ~mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_weight.exp()[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_weight.exp().squeeze().multinomial(1)[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test TSP Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets.tsp import gen_fully_connected_graph\n",
    "from environments.tsp import TSPEnv\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.utils import to_dense_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 10\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gen_fully_connected_graph(num_nodes)\n",
    "g_list = [g for _ in range(batch_size)]\n",
    "batch = Batch.from_data_list(g_list)\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_pos, dense_mask = to_dense_batch(batch.pos, batch.batch)\n",
    "assert dense_mask.all()\n",
    "node_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TSPEnv(node_pos)\n",
    "assert env.num_nodes == num_nodes\n",
    "assert env.batch_size == batch_size\n",
    "print(env._avail_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = env.random_action()\n",
    "env.step(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = False\n",
    "while not done:\n",
    "    state, reward, done, _ = env.step(env.random_action())\n",
    "state, reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test TSPAgent, TSPCritic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "import torch\n",
    "from datasets.tsp import gen_complete_graph\n",
    "from environments.tsp import TSPEnv\n",
    "from models.tsp_agent import TSPAgent\n",
    "from models.tsp_baseline import CriticBaseline\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.utils import to_dense_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 10\n",
    "batch_size = 64\n",
    "\n",
    "class args:\n",
    "    input_dim = 4\n",
    "    embed_dim = 64\n",
    "    num_embed_layers = 2\n",
    "    num_gnn_layers = 2\n",
    "    encoder_num_heads = 1\n",
    "    decoder_num_heads = 1\n",
    "    bias = True\n",
    "    pooling_method = \"add\"\n",
    "    decode_type = \"sampling\"\n",
    "    eval_batch_size = 64\n",
    "    warmup_batch_size = 256\n",
    "    device = torch.device(\"cp\")\n",
    "    max_grad_norm = 1.0\n",
    "    tanh_clipping = 0\n",
    "    normalization = \"batch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TSPAgent(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic = CriticBaseline(args).to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(param.numel() for param in critic.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = Batch.from_data_list([gen_fully_connected_graph(num_nodes) for _ in range(batch_size)])\n",
    "batch = batch.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_pos = to_dense_batch(batch.pos, batch.batch)[0]\n",
    "env = TSPEnv(node_pos)\n",
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encode(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_p_s = []\n",
    "selected_s = []\n",
    "reward_s = []\n",
    "done = False\n",
    "state = env.reset(node_pos)\n",
    "step = 0\n",
    "while (not done) and (step < 999):\n",
    "    selected, log_p = model(state)\n",
    "    state, reward, done, _ = env.step(selected)\n",
    "    log_p_s.append(log_p)\n",
    "    selected_s.append(selected)\n",
    "    reward_s.append(reward)\n",
    "    step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = torch.stack(selected_s, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logps = torch.stack(log_p_s, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihood = logps.gather(2, seqs).squeeze().sum(1)\n",
    "log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = model.encode(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "ll = logps[:, :, 1:]+0.001\n",
    "ll\n",
    "# loss = nn.NLLLoss()(, seqs.squeeze(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import BatchNorm\n",
    "norm = BatchNorm(args.embed_dim).to(args.device)\n",
    "norm(b.x.to(args.device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from args import get_args\n",
    "from datasets.tsp import TSPDataset\n",
    "from train import rollout, validate\n",
    "from rl_algorithms.reinforce import _calc_log_likelihood, clip_grad_norms\n",
    "from train import warmup_baseline\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TSPDataset(1000, args.graph_size, args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout(model, dataset, env, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate(model, dataset, env, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(\n",
    "    [{\"params\": model.parameters(), \"lr\": 0.001}] + \n",
    "    # [{\"params\": critic.parameters(), \"lr\": 0.001}]\n",
    ")\n",
    "# warmup_baseline(critic, dataset, env, optimizer, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(10)):\n",
    "    batch = batch.to(args.device)\n",
    "    model.train()\n",
    "    model.set_decode_type(\"sampling\")\n",
    "    log_p_s = []\n",
    "    selected_s = []\n",
    "    reward_s = []\n",
    "    done = False\n",
    "    state = env.reset(to_dense_batch(batch.pos, batch.batch)[0])\n",
    "    embed_data = model.init_embed(batch)\n",
    "    node_embeddings, graph_feat = model.encoder(embed_data)\n",
    "    fixed = model.precompute_fixed(node_embeddings, graph_feat)\n",
    "    step = 0\n",
    "    while (not done) and (step < 999):\n",
    "        selected, log_p = model(state, fixed)\n",
    "        state, reward, done, _ = env.step(selected)\n",
    "        log_p_s.append(log_p)\n",
    "        selected_s.append(selected)\n",
    "        reward_s.append(reward)\n",
    "        step += 1\n",
    "\n",
    "    _log_p = torch.stack(log_p_s, 1)\n",
    "    actions = torch.stack(selected_s, 1)\n",
    "    log_likelihood = _calc_log_likelihood(_log_p, actions)\n",
    "    reward = -(reward_s[-1])\n",
    "    # bl_val, bl_loss = critic.eval(batch, reward)\n",
    "    rl_loss = (reward*log_likelihood).mean()\n",
    "    # loss = rl_loss + bl_loss\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    rl_loss.backward()\n",
    "    grad_norms = clip_grad_norms(optimizer.param_groups, args.max_grad_norm)\n",
    "    optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(optimizer.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_log_p.exp().gather(2, actions).squeeze(-1)[0:8:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(_log_p[0].exp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(reward)\n",
    "# print(bl_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test MST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx.algorithms.tree.mst as mst\n",
    "from datasets.tsp import gen_fully_connected_graph\n",
    "from torch_geometric.transforms import distance\n",
    "from torch_geometric.utils import to_networkx, from_networkx, to_dense_batch\n",
    "from torch_geometric.data import Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = gen_fully_connected_graph(50)\n",
    "graph = Batch.from_data_list([graph] * 5)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = distance.Distance(cat=False)(graph)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng = to_networkx(graph, edge_attrs=[\"edge_attr\"], to_undirected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_mst = mst.minimum_spanning_tree(ng, \"edge_attr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mst_len = []\n",
    "for e in ng_mst.edges:\n",
    "    mst_len.append(ng_mst.edges[e][\"edge_attr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(mst_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "nx.draw(ng_mst, pos=graph.pos.numpy())\n",
    "ng_mst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([edge_value[\"edge_attr\"] for edge_value in ng_mst.edges.values()])\n",
    "mst_g = from_networkx(ng_mst)\n",
    "mst_b = Batch()\n",
    "mst_b.batch = graph.batch\n",
    "mst_b.edge_index = mst_g.edge_index\n",
    "mst_b.x = graph.x\n",
    "to_dense_batch(mst_b.x, mst_b.batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validateto_data_listto_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from args import get_args\n",
    "from environments.tsp import TSPEnv\n",
    "from models.tsp_agent import TSPAgent\n",
    "from train import rollout, validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args([])\n",
    "args.device = torch.device(\"cuda\")\n",
    "model = TSPAgent(args).to(args.device)\n",
    "model_path = \"/home/pxh/TSP-experiment/outputs/tsp_50/run_20201217T165809/epoch-21.pt\"\n",
    "dataste_path = \"/home/pxh/TSP-experiment/datasets/test/test-50-with-optimal.pk\"\n",
    "\n",
    "val_dataset = torch.load(dataste_path)\n",
    "load_data = torch.load(model_path)\n",
    "model.load_state_dict(load_data[\"model\"])\n",
    "env = TSPEnv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = rollout(model, val_dataset, env, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-out.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(torch.tensor([d.len for d in val_dataset]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1672.2463/569.4701"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Batch\n",
    "b = Batch.from_data_list([val_dataset[10]]).to(args.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset(b.pos.unsqueeze(0))\n",
    "logp_s = []\n",
    "done = False\n",
    "while not done:\n",
    "    model.eval()\n",
    "    model.set_decode_type(\"sampling\")\n",
    "    model.encode(b)\n",
    "    action, log_p = model(state)\n",
    "    logp_s.append(log_p)\n",
    "    state, r, done, _ = env.step(action)\n",
    "    \n",
    "-r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(49):\n",
    "#     plt.plot(torch.arange(logp_s[i].size(1)), logp_s[i].exp().detach().cpu().squeeze())\n",
    "#     plt.show()\n",
    "#     print(i)\n",
    "#     print(logp_s[i].exp().detach().cpu().squeeze().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mst_set = torch.load('/home/pxh/TSP-experiment/datasets/test/mst-10-100-optimal.pk')\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "tsp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in mst_set:\n",
    "    x.append(data.num_nodes)\n",
    "    y.append((data.concorde_len / data.mst_len).item())\n",
    "    tsp.append(data.concorde_len.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, tsp)"
   ]
  },
  {
   "source": [
    "## Test Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets.tsp\n",
    "from torch_geometric.transforms import Distance, KNNGraph\n",
    "from torch_geometric.utils import sort_edge_index\n",
    "from torch_geometric.nn import knn_graph\n",
    "from torch_geometric.data import Data\n",
    "import torch.multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lprun -f datasets.tsp.gen_fully_connected_graph -f datasets.tsp.gen_knn_graph -f Data.__init__ datasets.tsp.gen_knn_graph(50,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(datasets.tsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f  datasets.tsp.gen_complete_graph datasets.tsp.gen_complete_graph(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.reshape(index.T, [-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.stack(edge_attr.chunk(50)).squeeze().topk(k=5, dim=1, largest=False).indices[:, None, :].expand(50,2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = torch.stack(edge_index.chunk(50,dim=1)).gather(dim=2, index=idx)\n",
    "knn.permute(1,0,2).reshape(2,250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack(edge_attr.chunk(50)).squeeze().topk(k=5, dim=1, largest=False).values.reshape(250,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(knn1.edge_index==knn2.edge_index).all()"
   ]
  },
  {
   "source": [
    "## Test 2-opt environment"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import environments.tsp_2opt as env2opt\n",
    "import torch\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "reload(tsp2opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = tsp2opt.TSP2OPTEnv()\n",
    "node_pos = torch.empty((10, 5, 2)).uniform_(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset(T=10, node_pos=node_pos)\n",
    "state.curr_tour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = env.random_action()\n",
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s, r, d, _ = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.curr_tour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = []\n",
    "state = env.reset(T=100, node_pos=node_pos)\n",
    "done = False\n",
    "while not done:\n",
    "    action = env.random_action()\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    rewards.append(reward)\n",
    "torch.cat(rewards, dim=1).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.best_edge_list.shape"
   ]
  },
  {
   "source": [
    "## Test 2-opt model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<module 'models.tsp_2opt_agent' from '/home/pxh/Develope/TSP-experiment/models/tsp_2opt_agent.py'>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "import torch\n",
    "from datasets.tsp import gen_knn_graph\n",
    "import models.encoder as encoder\n",
    "import models.tsp_2opt_agent as tsp2opt\n",
    "import environments.tsp_2opt as env2opt\n",
    "from importlib import reload\n",
    "from torch_geometric.utils import to_undirected, remove_self_loops, contains_self_loops, to_dense_batch\n",
    "from torch_geometric.data import Batch\n",
    "from tqdm.notebook import tqdm\n",
    "reload(tsp2opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 20\n",
    "batch_size = 64\n",
    "\n",
    "class args:\n",
    "    graph_size = 20\n",
    "    node_dim = 2\n",
    "    edge_dim = 1\n",
    "    embed_dim = 64\n",
    "    num_gnn_layers = 2\n",
    "    tour_gnn_layers = 2\n",
    "    encoder_num_heads = 1\n",
    "    decoder_num_heads = 1\n",
    "    bias = True\n",
    "    pooling_method = \"mean\"\n",
    "    tour_pooling_method = \"add\"\n",
    "    decode_type = \"sampling\"\n",
    "    eval_batch_size = 64\n",
    "    warmup_batch_size = 256\n",
    "    device = torch.device(\"cuda\")\n",
    "    max_grad_norm = 1.0\n",
    "    tanh_clipping = 0\n",
    "    normalization = \"batch\"\n",
    "    graph_type = \"knn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = encoder.GNNEncoder(\n",
    "    args.embed_dim,\n",
    "    args.num_gnn_layers,\n",
    "    args.encoder_num_heads,\n",
    "    args.normalization,\n",
    "    pooling_method=args.pooling_method,\n",
    ")\n",
    "model = tsp2opt.TSP2OPTAgent(args)\n",
    "\n",
    "enc_optimizer = torch.optim.Adam(\n",
    "    [{\"params\": enc.parameters(), \"lr\": 0.0001}]\n",
    ")\n",
    "optimizer = torch.optim.Adam(\n",
    "    [{\"params\": model.parameters(), \"lr\": 0.0001}]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Batch(batch=[1280], edge_attr=[6400, 1], edge_index=[2, 6400], pos=[1280, 2], x=[1280, 4])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "batch = Batch.from_data_list([gen_knn_graph(num_nodes, 5) for _ in range(batch_size)])\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_data = model.init_embed(batch)\n",
    "embed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_embedding, _ = model.encoder(embed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = env2opt.TSP2OPTEnv()\n",
    "state = env.reset(T=10, node_pos=to_dense_batch(batch.pos, batch.batch)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected, log_p = model(state, node_embedding, embed_data.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_embedding.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_len = []\n",
    "best_len = []\n",
    "embed_data = model.init_embed(batch)\n",
    "embed_data.x = embed_data.x.detach()\n",
    "embed_data.edge_attr = embed_data.edge_attr.detach()\n",
    "node_embedding, _ = enc(embed_data)\n",
    "enc_optimizer.zero_grad()\n",
    "for _ in tqdm(range(50)):\n",
    "    done = False\n",
    "    log_p_s = []\n",
    "    action_s = []\n",
    "    reward_s = []\n",
    "    state = env.reset(T=20, node_pos=to_dense_batch(batch.pos, batch.batch)[0])\n",
    "    # embed_data = model.init_embed(batch)\n",
    "    # node_embedding, _ = model.encoder(embed_data)\n",
    "    while not done:\n",
    "        action, log_p = model(state, node_embedding, embed_data.batch)\n",
    "        state, reward, done, _ = env.step(action.squeeze())\n",
    "        log_p_s.append(log_p)\n",
    "        action_s.append(action)\n",
    "        reward_s.append(reward)\n",
    "    logps = torch.cat(log_p_s, dim=0)\n",
    "    actions = torch.cat(action_s, dim=0)\n",
    "    log_likelihood = logps.gather(-1, actions).sum(1)\n",
    "    R = torch.cat(reward_s, dim=0)\n",
    "    loss = (-log_likelihood*R).mean()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "\n",
    "    curr_len.append(state.curr_tour_len.mean())\n",
    "    best_len.append(state.best_tour_len.mean())\n",
    "    print(state.best_tour_len.mean().item())\n",
    "\n",
    "enc_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.curr_edge_list.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "done = False\n",
    "log_p_s = []\n",
    "action_s = []\n",
    "reward_s = []\n",
    "value_s = []\n",
    "state = env.reset(T=10, node_pos=to_dense_batch(batch.pos, batch.batch)[0])\n",
    "embed_data = model.init_embed(batch)\n",
    "node_embedding, _ = model.encoder(embed_data)\n",
    "while not done:\n",
    "    action, log_p, value = model(state, node_embedding, embed_data.batch)\n",
    "    state, reward, done, _ = env.step(action.squeeze())\n",
    "    log_p_s.append(log_p)\n",
    "    action_s.append(action)\n",
    "    reward_s.append(reward)\n",
    "    value_s.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logps = torch.stack(log_p_s, dim=0)\n",
    "actions = torch.stack(action_s, dim=0)\n",
    "log_likelihood = logps.gather(-1, actions).squeeze()\n",
    "R = torch.stack(reward_s, dim=0).expand_as(log_likelihood)\n",
    "loss = (-log_likelihood*R).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-34-70e951880730>:5: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n  x[0,0,0].grad\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones((512,64,128), requires_grad=True)\n",
    "y = torch.zeros_like(x, requires_grad=False)\n",
    "loss = (x - y).mean()\n",
    "loss.backward()\n",
    "x[0,0,0].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}